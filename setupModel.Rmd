---
title: "Setting up a zooplankton model using mizer"
author: Patrick Sykes and Julia L. Blanchard
date: July 22, 2020
place: Brisbane
output:
  html_document: default
---


# Introduction

Here we will recreate the ZooMSS model (version 2) in Heneghan et al. (2020 in preparation) using mizer.

We begin with some setup of required packages.

```{r setup, message=FALSE, warning=FALSE}
#get required packages
library(devtools)
#most up to date master branch of mizer
#install_github("sizespectrum/mizer")
#install_github("astaaudzi/mizer-rewiring", ref = "temp-model-comp")
#documentation here:
#https://sizespectrum.org/mizer/dev/index.html
library(mizer)
require(tidyverse)

#remotes::install_github("sizespectrum/mizerExperimental")
library(mizerExperimental)

```

### Data
Next, let's load in and check the data used in the ZooMSS model. TODO: add in some biomass data

```{r}

#read in group data
groups <-read.csv("data/TestGroups_mizer.csv")
groups$w_min <- 10^groups$w_min
groups$w_inf <- 10^groups$w_inf
groups$w_mat <- 10^groups$w_mat
#groups<-merge(groups,dat,by.x="species",by.y="group",all=T)

# have a look at plot
# plot(groups$w_inf,groups$biomass.tperkm2,xlab="log Maximum Weight [g]", ylab=" log Total Biomass", log="xy",col="blue",pch=16)
# text(groups$w_inf,groups$biomass.tperkm2,labels=groups$species,cex=0.5)

# could plot the paramter allometries here to explore
```


## Set-up mizer model

Next let's read in the parameters from ZooMSS.

```{r}
#read groups again for southern ocean model, this time subsetting key groups
groups <-read.csv("data/TestGroups_mizer.csv")
groups$w_min <- 10^groups$w_min #convert from log10 values
groups$w_inf <- 10^groups$w_inf
groups$w_mat <- 10^groups$w_mat
groups$h <- 1e50 # should be Inf, but that breaks the calculations. Massive value still works out to effectively unlimited feeding as allowed in ZooMSS
groups$ks <- 0 #turn off standard metabolism
#todo - ramp up constant repro for coexistence

#groups <- readRDS("data/groups.RDS")[-1,]
#check fails these tests:
#groups$w_mat25 >= groups$w_mat #note we don't have w_mat25. Not sure if it's necessary/desirable. Probably not.
groups$w_mat <= groups$w_min
groups$w_inf <= groups$w_mat



# read interaction matrix
# get the interaction matrix - actually I think we can leave this out. Default is all 1s, which is the same as in ZooMSS. Included for completeness; it may be useful in future to keep this in.
theta <- readRDS("data/zoomss_inter.rds")[,-1]
#[-1,-1]

 
```

We will pass these parameters to mizer to set up a new multispecies model.

TODO: adjust parameters here.

```{r}


ID <- 1 #index of environmental data to choose
enviro_row <- readRDS("data/envirofull_20200317.RDS")[ID,]

#set up the fixed phyoplankton spectrum
phyto_fixed <- function(params, n, n_pp, n_other, rates, dt = 0.01, kappa = 10^enviro_row$phyto_int, lambda = 1-enviro_row$phyto_slope,...) {
    n_pp <- kappa*params@w_full^(-lambda) #returns the fixed spectrum at every time step
    n_pp[params@w_full>params@resource_params$w_pp_cutoff] <- 0
    return(n_pp)
}

mf.params <- newMultispeciesParams(species_params=groups,
                                   interaction=NULL, #NULL sets all to 1, no strict herbivores
                                   no_w = 178, #number of zoo+fish size classes;
                                   min_w_pp = 10^(-14.4), #minimum phyto size. Note: use -14.4, not -14.5, otherwise it makes an extra size class
                                   w_pp_cutoff = 10^(enviro_row$phyto_max), #maximumplot phyto size
                                   n = 0.7, #The allometric growth exponent used in ZooMSS
                                   z0pre = 1, #external mortality (senescence)
                                   z0exp = 0.3,
                                   resource_dynamics = "phyto_fixed",
                                   kappa = 10^(enviro_row$phyto_int), 
                                   lambda = -enviro_row$phyto_slope+1,
                                   RDD = constantRDD(species_params = groups) #first go at this
                                   #pred_kernel = ... #probably easiest to just import this/pre-calculate it, once dimensions are worked out
)

#checks
length(which(mf.params@initial_n_pp>0)) == length(seq(-14.5,enviro_row$phyto_max, by = 0.1))


```


Now do some fiddling to make the new MizerParams object match the ZooMSS parameters. Note: this chunk is adapted from `fZooMSS_setup.R`, found at https://github.com/MathMarEcol/ZooMSS/.

```{r}
setZooMizerConstants <- function(params, Groups, input_params){
#### CALCULATES CONSTANT BITS OF THE MODEL FUNCTIONS FOR EACH GROUP
  SearchVol <- getSearchVolume(params)
  M_sb <- getExtMort(mf.params)
  ZSpre <- 1 # senescence mortality prefactor
  ZSexp <- 0.3 # senescence mortality exponent
  
  pred_kernel <- getPredKernel(params)
  prey_weight_matrix <- matrix(params@w_full, nrow = length(params@w), ncol = length(params@w_full), byrow = TRUE)
  pred_weight_matrix <- matrix(params@w, nrow = length(params@w), ncol = length(params@w_full))
  
  for(i in 1:nrow(params@species_params)){
    ## Senescence mortality
    if(params@species_params$Type[i] == "Zooplankton"){
      M_sb[i,] <- ZSpre*(params@w/(10^(params@species_params$w_mat[i])))^ZSexp
      M_sb[i, 10^(params@species_params$w_max[i]) < params@w] <- 0
      M_sb[i, 10^(params@species_params$w_mat[i]) > params@w] <- 0
    }
    
    if(params@species_params$Type[i] == "Fish"){
      M_sb[i,] <- 0.1*ZSpre*(params@w/(10^(params@species_params$w_mat[i])))^ZSexp
      M_sb[i, 10^(params@species_params$w_max[i]) < params@w] <- 0
      M_sb[i, 10^(params@species_params$w_mat[i]) > params@w] <- 0
    }
    
    ### Search volume
    SearchVol[i,] <- (params@species_params$gamma[i])*(params@w^(params@species_params$gamma[i]))
    SearchVol[i, 10^(params@species_params$w_max[i]) < params@w] <- 0
    SearchVol[i, 10^(params@species_params$w_min[i]) > params@w] <- 0
    
    ### Predation Kernels
    if(is.na(params@species_params$PPMRscale[i]) == FALSE){ # If group has an m-value (zooplankton)
      # Calculate PPMR for zooplankton, which changes according to body-size (Wirtz, 2012)
      D.z <- 2*(3*params@w*1e12/(4*pi))^(1/3) # convert body mass g to ESD (um)
      betas <- (exp(0.02*log(D.z)^2 - params@species_params$PPMRscale[i] + 1.832))^3 # Wirtz's equation
      beta_mat <- matrix(betas, nrow = length(params@w), ncol = length(mf.params@w_full))
      
      # Calculate feeding kernels
      pred_kernel[i, , ] <- exp(-0.5*(log((beta_mat*prey_weight_matrix)/
                                     pred_weight_matrix)/params@species_params$FeedWidth[i])^2)/
        sqrt(2*pi*params@species_params$FeedWidth[i]^2)
      # The feeding kernel of filter feeders is not expected to change much with increasing size so we fix it here
      
      # if (param$fixed_filterPPMR == TRUE){
      if(i == 3){
        pred_kernel[i, , ] <- matrix(pred_kernel[i,44,], nrow = length(params@w), ncol = length(mf.params@w_full), byrow = TRUE)
      }
      if(i == 8){
        pred_kernel[i, , ] <- matrix(pred_kernel[i,61,], nrow = length(params@w), ncol = length(mf.params@w_full), byrow = TRUE)
      }
      # }
      
    } else { # If group does not have an m-value (fish)
      beta_mat <- matrix(params@species_params$PPMR[i], nrow = length(params@w), ncol = length(params@w_full))
      
      # Calculate feeding kernels
      pred_kernel[i, , ] <- exp(-0.5*(log((beta_mat*prey_weight_matrix)/
                                             pred_weight_matrix)/params@species_params$FeedWidth[i])^2)/
        sqrt(2*pi*params@species_params$FeedWidth[i]^2)
    }

  }
  
  #temperature effect 
  temp_eff <-  matrix(2.^((input_params$sst - 30)/10), nrow = length(params@species_params$species), ncol = length(params@w))
  M_sb <- temp_eff * M_sb # Incorporate temp effect on senscence mortality
  
params <- setExtMort(params, z0 = M_sb)
params <- setSearchVolume(params, SearchVol)
params <- setPredKernel(params, pred_kernel)

}

setZooMizerConstants(mf.params, groups, enviro_row)


```

Try running it:

```{r}

mf.params <- setParams(mf.params)

sim <- project(mf.params, t_max=100,dt = 0.01)
plot(sim) #note feeding level means satiation - 0 since there's no satiation in this model.
plotlyBiomass(sim)
#plotlyGrowthCurves(sim,species="macrozooplankton")
plotlyFeedingLevel(sim)
# feeding level satiation for some groups, except for the seabirds
# macrozooplankton - they are not growing enough,why?
#tuneParams(mf.params)
plotlyGrowthCurves(sim,percentage = T)
plotlySpectra(sim)
```


Next thing to do is reproduction. In ZooMSS, this is handled by simply setting the abundance in the smallest size class to be a fixed proportion of the community size spectrum; in short

$$ N_i(w_{min}(i)) = prop(i) \sum_{j \neq i} N_j(w_{min}(i)),$$
where $N_i(w)$ is the density of species $i$ in weight class $w$, and $prop(i)$ is a (fixed) proportion depending on the species.

In mizer, reproduction is linked to metabolism. The abundance in the smallest size class is proportional to the energy available to mature individuals for reproduction - i.e. the energy left over after subtracting metabolic costs (including energy to support growth) from the energy assimilated (by mature individuals) from feeding on prey.

Now, to recreate this in mizer, we need to rewrite mizer's `project_simple()` function. We do this by making a new function, `new_project_simple()`, and using it in place of the default one:

```{r}
new_project_simple <- function(params, n, n_pp, n_other, t, dt, steps, 
                           effort, resource_dynamics_fn, other_dynamics_fns,
                           rates_fns, ...) {    
    # Handy things
    no_sp <- nrow(params@species_params) # number of species
    no_w <- length(params@w) # number of fish size bins
    idx <- 2:no_w
    w_max_idx <- params@w_min_idx
    for (i in 1:length(w_max_idx)) {
     w_max_idx[i] <- which(round(log10(params@w),2)==round(log10(params@species_params$w_inf[i]),2)) 
    }
    
    # Hacky shortcut to access the correct element of a 2D array using 1D notation
    # This references the egg size bracket for all species, so for example
    # n[w_min_idx_array_ref] = n[,w_min_idx]
    w_min_idx_array_ref <- (params@w_min_idx - 1) * no_sp + (1:no_sp)
    # Matrices for solver
    a <- matrix(0, nrow = no_sp, ncol = no_w)
    b <- matrix(0, nrow = no_sp, ncol = no_w)
    S <- matrix(0, nrow = no_sp, ncol = no_w)
    
    for (i_time in 1:steps) {
        r <- rates_fns$Rates(
            params, n = n, n_pp = n_pp, n_other = n_other,
            t = t, effort = effort, rates_fns = rates_fns, ...)
        
        # Update time
        t <- t + dt
        
        # Update other components
        n_other_current <- n_other  # So that the resource dynamics can still 
        # use the current value
        for (component in names(params@other_dynamics)) {
            n_other[[component]] <-
                other_dynamics_fns[[component]](
                    params,
                    n = n,
                    n_pp = n_pp,
                    n_other = n_other_current,
                    rates = r,
                    t = t,
                    dt = dt,
                    component = component,
                    ...
                )
        }
        
        # Update resource
        n_pp <- resource_dynamics_fn(params, n = n, n_pp = n_pp,
                                     n_other = n_other_current, rates = r,
                                     t = t, dt = dt, ...)
        
        # Iterate species one time step forward:
        # a_{ij} = - g_i(w_{j-1}) / dw_j dt
        a[, idx] <- sweep(-r$e_growth[, idx - 1, drop = FALSE] * dt, 2,
                          params@dw[idx], "/")
        # b_{ij} = 1 + g_i(w_j) / dw_j dt + \mu_i(w_j) dt
        b[] <- 1 + sweep(r$e_growth * dt, 2, params@dw, "/") + r$mort * dt
        # S_{ij} <- N_i(w_j)
        S[,idx] <- n[, idx, drop = FALSE]
        # Update n
        # for (i in 1:no_sp) # number of species assumed small, so no need to 
        #                      vectorize this loop over species
        #     for (j in (params@w_min_idx[i]+1):no_w)
        #         n[i,j] <- (S[i,j] - A[i,j]*n[i,j-1]) / B[i,j]
        # This is implemented via Rcpp
        n <- inner_project_loop(no_sp = no_sp, no_w = no_w, n = n,
                                A = a, B = b, S = S,
                                w_min_idx = params@w_min_idx)
    }
        
        # Update first and last size groups of n
        #TODO: Make this a little less hacky
        n[1,1] <- params@species_params$Prop[1]*n_pp[length(params@w_full)-length(params@w)+1]
        n[1,w_max_idx[1]] <- 0
        for (i in 2:no_sp) {
          n[i, w_max_idx[i]] <- 0
          if(params@species_params$Type[i] != "Fish"){
            n[i,params@w_min_idx[i]] <- params@species_params$Prop[i] * sum(n[-i,params@w_min_idx[i]])
            }
          if(params@species_params$Type[i] == "Fish"){
            n[i,params@w_min_idx[i]] <- 1/3 * sum(n[1:9,params@w_min_idx[i]])
            }
        }
            
    return(list(n = n, n_pp = n_pp, n_other = n_other, rates = r))
}


#assign new project function in namespace
environment(new_project_simple) <- asNamespace('mizer')
assignInNamespace("project_simple", new_project_simple, ns = "mizer")
```


Now let's try that out:

```{r}
sim2 <- project(mf.params, t_max = 100, dt = 0.01)
plot(sim2)
```

Still missing is the differential prey nutrition based on prey carbon content. We'll do that by editing the `mizerEncounter()` function found in `project_methods.R`, and using `setRateFunction(params, "Encounter", "myEncounter")`. It might be possible to instead edit the chunk above too to incorporate the different method (since we've gone there anyway...)

```{r}

#set up matrix of pred nutrition given prey, dims (pred species) x (prey species)
assim_eff = matrix(mf.params@species_params$GrossGEscale * mf.params@species_params$Carbon, nrow = nrow(mf.params@species_params), ncol = nrow(mf.params@species_params))
get_filterfeeders <- which(mf.params@species_params$FeedType == "FilterFeeder")

for (i in get_filterfeeders) {
  assim_eff[,i] <- assim_eff[,i] / mf.params@species_params$Carbon[i]
}

new_Encounter <- function(params, n = params@initial_n, 
                         n_pp = params@initial_n_pp,
                         B = params@initial_B) {

    # idx_sp are the index values of params@w_full such that
    # params@w_full[idx_sp] = params@w
    idx_sp <- (length(params@w_full) - length(params@w) + 1):length(params@w_full)
    
    # Note: removed the FFT code because it does not apply to this case.
    
    # n_eff_prey is the total prey abundance by size exposed to each
    # predator (prey not broken into species - here we are just working out
    # how much a predator eats - not which species are being eaten - that is
    # in the mortality calculation
    # \sum_j \theta_{ij} N_j(w_p) w_p dw_p
    n_eff_prey <- sweep(params@interaction %*% n, 2, 
                        params@w * params@dw, "*", check.margin = FALSE) 
    # pred_kernel is predator species x predator size x prey size
    # So multiply 3rd dimension of pred_kernel by the prey biomass density
    # Then sum over 3rd dimension to get consumption rate of each predator by 
    # predator size
    # This line is a bottle neck
    phi_prey_species <- rowSums(sweep(
      params@pred_kernel[, , idx_sp, drop = FALSE],
      c(1, 3), n_eff_prey, "*", check.margin = FALSE), dims = 2)
    # Eating the background
    # This line is a bottle neck
    phi_prey_background <- params@species_params$interaction_p *
      rowSums(sweep(
        params@pred_kernel, 3, params@dw_full * params@w_full * n_pp,
        "*", check.margin = FALSE), dims = 2)
    encounter <- params@search_vol * (phi_prey_species + phi_prey_background)
    dimnames(encounter) <- dimnames(params@metab)
    
    # Add contribution from unstructured resources
    # Can't use rowSums or colSums unfortunately because
    # the resource index that we want to sum over is the middle index.
    for (u in seq_along(B)) {
        encounter[] <- encounter + params@rho[, u, ] * B[u]
    }
    return(encounter)
}

setRateFunction(params, "Encounter", "new_Encounter")
```

<!-- ```{r} -->

<!-- ####### psi function -->

<!-- #   # change allocation to reproduction = check for endotherms/determinate growers (should be 1 at wmat not winf) -->
<!-- #  psi_r=20 -->
<!-- #  params@psi[] <- unlist(tapply(params@w,1:length(params@w),function(wx,winf,wmat,n){ -->
<!-- #    ((1 + (wx/(wmat))^-psi_r)^-1) * (wx/winf)^(1-n)},winf=params@species_params$w_inf,wmat=params@species_params$w_mat,n=params@n)) -->
<!-- # # # set w < 1% of wmat to 0 -->
<!-- #  params@psi[unlist(tapply(params@w,1:length(params@w),function(wx,wmat)wx<(wmat*0.01),wmat=params@species_params$w_mat))] <- 0 -->
<!-- # # # set all m > m to 1 # check this is right... -->
<!-- #  params@psi[unlist(tapply(params@w,1:length(params@w),function(wx,winf)(wx/winf)>1,winf=params@species_params$w_inf))] <- 1 -->
<!-- # -->
<!-- # ########## erepro -->
<!-- # -->
<!-- #  #and erepro - should this decline with winf or shoudl it just be a very small number 0.005? -->
<!-- # #should this actually be closer to 1 for mammals? -->
<!-- # params@species_params$erepro <-0.05*params@species_params$w_inf^(-0.75) -->
<!-- # # need to think about how this sounds in writing -->
<!-- # -->
<!-- # ######### juvenile mortality -->
<!-- # -->
<!-- # ## add declining intraspecific juvenile mortality to background mortality -->
<!-- # for (i in 1: length(params@species_params$species)) params@mu_b[i,] <- params@mu_b[i,]  + 0.1*params@w^-0.25 -->
<!-- # -->


<!-- ``` -->

<!-- Let's take a look now. -->
<!-- ```{r} -->

<!-- params<- setParams(params, pred_kernel = pred_kern,kappa=1e6) -->

<!-- # run again, intialised from the final state above -->
<!-- new.mf<-project(params,t_max=100,initial_n=sim@n[500,,],initial_n_pp=sim@n_pp[500,]) -->

<!-- #plot(new.mf) -->

<!-- # run again for longer, from the final state above -->
<!-- #new.mf<-project(params,t_max=500,initial_n=new.mf@n[100,,],initial_n_pp=new.mf@n_pp[100,]) -->

<!-- plot(new.mf)   -->
<!-- plotlyFeedingLevel(new.mf)   -->
<!-- plotlyGrowthCurves(new.mf,percentage = T)  -->
<!-- plotlyBiomass(new.mf,percentage = T)  -->
<!-- plotBioData(new.mf,dat) -->

<!-- ``` -->

<!-- That helps baleen whales - and impact macrozoooplankton, but some of the predator groups are still not getting enough food. -->

<!-- ### Prey size selection -->

<!-- What range of values should the seabirds have - should we use a box kernel for those groups? I seem to remember there are distinct size ranges for the different seabirds. -->

<!-- ### Metabolic costs -->

<!-- Are these correct for the different groups? What about the maximum intake rate coefficients - h? Do these sclae in the way that is expected for endotherms? -->

<!-- ### Maturation and reproduction -->

<!-- We need to check the assumptions about maturation and reproduction for the non-fish groups. -->

<!-- The marine mammals and seabirds show stop growth once they reach maturation size. Need to make sure some functioanl groups are not mixtures of these type of taxa. Therefore matruation size and asymptotic size are very close. They should probably alos follow a sharp transition to maturation size, as they follow determinate growth. -->

<!-- Density dependence: Erepro, Rmax. -->

<!-- Should we change the reproduction function to not use the stock-recruitmnet assumption? There are other options now:https://sizespectrum.org/mizer/reference/index.html#section-density-dependent-reproduction -->


<!-- ### Starvation mortality -->

<!-- Should we include startvation morality ? This would free up competition for resources.... -->



<!-- ### Other sources of mortality -->

<!-- Currently assumong a fairly low backgournd "other" moratlity that is constant within fucntioan group but declines with aymptotic size (Brown et al. 2004). Sensescence mortality has been used in other work, but is tricky to parameterise. Though this might be needed for squid or other life histories that dies after reproduction. -->

<!-- ### Plankton dynamics -->

<!-- Currently we use the default plankton dynamics and parameter values. What should these be for the Southern Ocean? Do we have any information from regional shelf sea biogeochmical models? The previous information of satellite data seem limited.  -->

<!-- So, we decided to ask the question: What does the plankton need to be to feed the rest of the size spectrum (at equlibrium)? Does anyone have size spectrum slopes and intercepts for this system? (Angus Atkinson?) -->

<!-- However, we could also incude stochasticity...more work though example here: https://rpubs.com/gustav/plankton-anchovy -->

<!-- Samik Datta and I have also looked at seasonality - hopefully will build extension, but how important for this? -->

<!-- # Model Calibration  -->

<!-- WARNING: BELOW IS UNFINISHED AND DOES NOT CURRENTLY WORK. SHOULD WE START SIMPLER BASIC CALIBRATION ? I HAVE NOT WORKED OUT  MIKE'S METHOD YET. -->

<!-- Rather than continue to manually adjust and tune the parameters we will try to automatically calibrate the model with data and estimate our uncertain parameters. We are particularly uncertian about: kappa ( the satellite data used as  inputs does not appear to be enough to keep the zooplankton  grooups alive), Rmax( this will influence the biomass of each group) Here, we will use an inverse calibraion where we have population level biomass density data for 6 of the marine mammal and seabird groups (obtained from the inputs for an EcoPath model).  -->

<!-- ```{r} -->
<!-- # Step 0. Set up function to run model and output the predicted log biomasses -->

<!-- runmodel<-function(theta,parms=params,delta_t=0.1){# set up and run! -->
<!-- # change the paramters values that we want to estimate/calibrate -->
<!-- parms@species_params$R_max<- theta[1]*parms@species_params$w_inf^theta[2] -->
<!-- kappa <- theta[3] -->
<!-- backmort <- theta[4] -->
<!-- parms<-setParams(parms,kappa=kappa,z0pre = backmort) -->
<!-- #parms<- setPredKernel(parms, pred_kernel) -->
<!-- sim<- project(parms,dt=delta_t,t_max = 100) -->
<!-- # output the biomass denisty in terms of tonnes per km2 -->
<!-- # assume model is set up for an area of 1km2 -->
<!-- # this will output the biomass at last time step - do we need a time-average? -->
<!-- sim_logbiomass<-log(getBiomass(sim)[dim(sim@n)[1],]) - log(1e6) -->
<!-- return(sim_logbiomass) -->
<!-- # do we also want to pass the equilibrium n and n_pp from last iteration? -->
<!-- } -->
<!-- #test-run -->

<!-- theta <- c(1e2,-1.5,1e5,0.1) -->
<!-- runmodel(theta = theta,parms=mf.params) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- # set up error function to compare predictions with observations (only need range of observations) -->
<!-- dat<-log(c(rep(NA,4),0.003451, 0.015580,NA,NA,0.258995,0.008246,0.021900,0.141530)) -->
<!-- names(dat) <-params@species_params$species -->

<!-- sse <- function(theta, params=params,dat=dat) { -->
<!-- pred <- runmodel(theta,params) -->
<!-- # sum of squared errors, here on log-scale of predictions and data (can change this) -->
<!-- discrep <- pred[!is.na(dat)] - dat[!is.na(dat)] -->
<!-- return(sum(discrep^2)) -->
<!-- } -->
<!-- err<-sse(theta,mf.params,dat) -->
<!-- #test -->
<!-- err -->
<!-- ``` -->




<!-- We could skip ahead to  optimisation here to simply find the "best" single parameter values given the model and the data. Or carry out more advance Bayeisan methods. Instead, to illustrate how this works and to examine the error surface, we will set up a simple grid of parameters. Because the models runs are not actually dependent on each other (they are sequential), we can also do this much more quickly with parallel computing.  -->

<!-- ```{r} -->


<!-- # below not working -->



<!-- # two parameter grid -->
<!-- kappa <- seq(from=0.05,to=0.1,by=0.05) -->
<!-- effort <- seq(from=0,to=2,by=0.1) -->
<!-- grid <- expand.grid(kappa=kappa,effort=effort) -->
<!-- grid$SSE <- apply(grid,1,f) -->



<!-- #optimisation -->
<!-- vals<-optim(par=c(1e3,0.1),sse,method ="SANN") -->

<!-- # two parameter grid -->
<!-- kappa <- seq(from=0.05,to=0.1,by=0.05) -->
<!-- mort <- seq(from=0,to=2,by=0.1) -->
<!-- grid <- expand.grid(kappa=kappa,mort=mort) -->
<!-- grid$SSE <- apply(grid,1,sse) -->


<!-- ``` -->



<!-- ###### Bayesian in a week -->


<!-- ```{r} -->
<!-- ## Step 1. generate parameter sets to sample and plug in to model -->
<!-- library(randtoolbox) -->
<!-- library(boot) -->
<!-- #### generate Round  1 -->
<!-- theta <- sobol(n = 20000, dim = 26) -->
<!-- for(i in 1:12){ -->
<!--   # Rmax -->
<!--   theta[,i] <- c(10,10,14,18,12,10,14,15)+ theta[,i] * c(20,19,16,13,18,20,16,15) -->
<!-- } -->
<!--   #erepro -->
<!-- for(i in 13:24){ -->
<!--   theta[,i] <-  inv.logit(-5 + theta[,i] * 5) -->
<!-- } -->
<!--  #kappa -->
<!-- theta[,25] <- 5 + theta[,25] * 25 -->

<!--  #background mort -->
<!-- theta[,26] <- inv.logit(-5 + theta[,26] * 5) -->


<!-- ``` -->



<!-- ```{r} -->
<!-- #### Run Model (could set up on cluster, but nice to have prgress bar) -->

<!-- library(pbapply) -->
<!-- round_1 <-  pbapply(theta,1,runmodel, parms) -->
<!-- save(theta,round_1,file="data/round1.Rdata") -->

<!-- ``` -->

<!-- ```{r} -->
<!-- # set up error function to compare predictions with observations (only need range of observations) -->
<!-- ## Calculate the difference between the simulated catches and the observations. plot the results -->
<!-- load("data/round1.Rdata") -->
<!-- difs<- pbsapply(1:nrow(theta),function(x){colSums((matrix(round_1[,x],ncol=8) - log(dat[,-1]))^2,na.rm=T)}) -->


<!-- ``` -->

<!-- ```{r} -->
<!-- # build emulator on diffs -->
<!-- ``` -->


<!-- ```{r} -->
<!-- # sample and cheick params work -->
<!-- ``` -->


<!-- ```{r} -->
<!-- # MCMC - posterior -->
<!-- ``` -->


<!-- ```{r} -->
<!-- # resample posterior and compare emulator wth mizer (get importance weightings) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- # resample posterior accordingto weights & run mize scenarios -->
<!-- ``` -->